import gradio as gr
import argparse
import torchaudio
from tts import StepAudioTTS
from tokenizer import StepAudioTokenizer
from datetime import datetime
import os
from fastapi import FastAPI, HTTPException, Depends, Query, Body, File, UploadFile, Form
from fastapi.security import APIKeyHeader
from fastapi.openapi.docs import get_swagger_ui_html, get_redoc_html
from fastapi.openapi.utils import get_openapi
from fastapi.responses import FileResponse
from typing import Optional, Dict, Any, List
from pydantic import BaseModel
from status_tracker import StatusTracker

# æ·»åŠ Tokenè®¤è¯é…ç½®
DEFAULT_TOKEN = "step_audio_778899"
AUTH_TOKEN = os.environ.get("STEP_AUDIO_TOKEN", DEFAULT_TOKEN)

# ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼è®¾ç½®ç›®å½•
MODELS_DIR = os.environ.get("MODELS_DIR", "./models")
CONFIG_DIR = os.environ.get("CONFIG_DIR", "./config")
DATA_DIR = os.environ.get("DATA_DIR", "./data")
LOGS_DIR = os.environ.get("LOGS_DIR", "./logs")
CACHE_DIR = os.environ.get("CACHE_DIR", os.path.join(DATA_DIR, "cache"))

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(os.path.join(DATA_DIR, "output", "common"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "output", "music"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "output", "clone"), exist_ok=True)
os.makedirs(os.path.join(DATA_DIR, "cache"), exist_ok=True)

# åˆ›å»ºçŠ¶æ€è·Ÿè¸ªå™¨ï¼ˆå¦‚æœapp.pyæœªå¯åŠ¨åˆ™åˆ›å»ºæ–°çš„ï¼Œå¦åˆ™å°è¯•å¤ç”¨ï¼‰
try:
    from app import status_tracker
    print("å¤ç”¨app.pyä¸­çš„çŠ¶æ€è·Ÿè¸ªå™¨")
except ImportError:
    status_tracker = StatusTracker()
    print("åˆ›å»ºæ–°çš„çŠ¶æ€è·Ÿè¸ªå™¨")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="Step-Audio TTS API",
    description="Step-Audio è¯­éŸ³åˆæˆæœåŠ¡API",
    version="1.0.0",
    docs_url=None,
    redoc_url=None,
)

# APIå®‰å…¨ç›¸å…³
api_key_header = APIKeyHeader(name="X-API-KEY", auto_error=False)

# Pydanticæ¨¡å‹ç”¨äºAPIè¯·æ±‚å’Œå“åº”
class TTSCommonRequest(BaseModel):
    text: str
    speaker: str = "Tingting"
    emotion: Optional[str] = None
    language: Optional[str] = None
    speed: Optional[str] = None
    token: str

class TTSMusicRequest(BaseModel):
    text: str
    speaker: str = "Tingting"
    mode: str = "RAP"
    token: str

class TTSResponse(BaseModel):
    status: str
    file_path: str
    text: str
    speaker: str
    params: Dict[str, Any]

# è‡ªå®šä¹‰æ–‡æ¡£è·¯ç”±
@app.get("/docs", include_in_schema=False)
async def custom_swagger_ui_html():
    """è‡ªå®šä¹‰Swagger UIé¡µé¢è·¯ç”±"""
    return get_swagger_ui_html(
        openapi_url="/openapi.json",
        title=app.title + " - Swagger UI",
        oauth2_redirect_url=app.swagger_ui_oauth2_redirect_url,
        swagger_js_url="https://cdn.jsdelivr.net/npm/swagger-ui-dist@5/swagger-ui-bundle.js",
        swagger_css_url="https://cdn.jsdelivr.net/npm/swagger-ui-dist@5/swagger-ui.css",
    )

@app.get("/redoc", include_in_schema=False)
async def redoc_html():
    """è‡ªå®šä¹‰ReDocé¡µé¢è·¯ç”±"""
    return get_redoc_html(
        openapi_url="/openapi.json",
        title=app.title + " - ReDoc",
        redoc_js_url="https://cdn.jsdelivr.net/npm/redoc@next/bundles/redoc.standalone.js",
    )

@app.get("/openapi.json", include_in_schema=False)
async def get_open_api_endpoint():
    """OpenAPI schemaç«¯ç‚¹"""
    return get_openapi(
        title=app.title,
        version=app.version,
        description=app.description,
        routes=app.routes,
    )

# ä¾èµ–å‡½æ•°ï¼Œç”¨äºAPIè®¤è¯
async def verify_token(api_key: str = Depends(api_key_header)):
    if api_key == AUTH_TOKEN:
        return True
    raise HTTPException(
        status_code=401,
        detail="æ— æ•ˆçš„APIå¯†é’¥",
        headers={"WWW-Authenticate": "Bearer"},
    )

# Tokenè®¤è¯éªŒè¯å‡½æ•°
def validate_token(token):
    """éªŒè¯ç”¨æˆ·è¾“å…¥çš„tokenæ˜¯å¦æœ‰æ•ˆ"""
    if token == AUTH_TOKEN:
        return True
    return False

# ä¿å­˜éŸ³é¢‘
def save_audio(audio_type, audio_data, sr):
    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    save_path = os.path.join(DATA_DIR, "output", audio_type, f"{current_time}.wav")
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    torchaudio.save(save_path, audio_data, sr)
    return save_path


# æ™®é€šè¯­éŸ³åˆæˆï¼ˆæ·»åŠ Tokenè®¤è¯ï¼‰
def tts_common(text, speaker, emotion, language, speed, token):
    # éªŒè¯token
    if not validate_token(token):
        gr.Warning("è®¤è¯å¤±è´¥ï¼Œè¯·è¾“å…¥æœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
        return None
        
    text = (
        (f"({emotion})" if emotion else "")
        + (f"({language})" if language else "")
        + (f"({speed})" if speed else "")
        + text
    )
    output_audio, sr = tts_engine(text, speaker)
    audio_type = "common"
    common_path = save_audio(audio_type, output_audio, sr)
    return common_path


# RAP / å“¼å”±æ¨¡å¼ï¼ˆæ·»åŠ Tokenè®¤è¯ï¼‰
def tts_music(text_input_rap, speaker, mode_input, token):
    # éªŒè¯token
    if not validate_token(token):
        gr.Warning("è®¤è¯å¤±è´¥ï¼Œè¯·è¾“å…¥æœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
        return None
        
    text_input_rap = f"({mode_input})" + text_input_rap
    output_audio, sr = tts_engine(text_input_rap, speaker)
    audio_type = "music"
    music_path = save_audio(audio_type, output_audio, sr)
    return music_path


# è¯­éŸ³å…‹éš†ï¼ˆæ·»åŠ Tokenè®¤è¯ï¼‰
def tts_clone(text, wav_file, speaker_prompt, emotion, language, speed, token):
    # éªŒè¯token
    if not validate_token(token):
        gr.Warning("è®¤è¯å¤±è´¥ï¼Œè¯·è¾“å…¥æœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
        return None
        
    clone_speaker = {
        "wav_path": wav_file,
        "speaker": "custom_voice",
        "prompt_text": speaker_prompt,
    }
    clone_text = (
        (f"({emotion})" if emotion else "")
        + (f"({language})" if language else "")
        + (f"({speed})" if speed else "")
        + text
    )
    output_audio, sr = tts_engine(clone_text, "", clone_speaker)
    audio_type = "clone"
    clone_path = save_audio(audio_type, output_audio, sr)
    return clone_path


# APIè·¯ç”± - TTSç›¸å…³æ¥å£
@app.post("/api/tts/common", response_model=TTSResponse, tags=["TTS"])
async def api_tts_common(request: TTSCommonRequest, auth: bool = Depends(verify_token)):
    """TTSæ™®é€šè¯­éŸ³åˆæˆAPIï¼Œæ”¯æŒæƒ…æ„Ÿã€è¯­è¨€å’Œè¯­é€Ÿæ§åˆ¶"""
    if not validate_token(request.token):
        raise HTTPException(status_code=401, detail="è®¤è¯å¤±è´¥ï¼Œè¯·æä¾›æœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
    
    text_processed = (
        (f"({request.emotion})" if request.emotion else "")
        + (f"({request.language})" if request.language else "")
        + (f"({request.speed})" if request.speed else "")
        + request.text
    )
    output_audio, sr = tts_engine(text_processed, request.speaker)
    audio_type = "common"
    file_path = save_audio(audio_type, output_audio, sr)
    
    return {
        "status": "success",
        "file_path": file_path,
        "text": request.text,
        "speaker": request.speaker,
        "params": {
            "emotion": request.emotion,
            "language": request.language,
            "speed": request.speed
        }
    }

@app.post("/api/tts/music", response_model=TTSResponse, tags=["TTS"])
async def api_tts_music(request: TTSMusicRequest, auth: bool = Depends(verify_token)):
    """TTSéŸ³ä¹/å“¼å”±æ¨¡å¼APIï¼Œæ”¯æŒRAPå’Œå“¼å”±æ¨¡å¼"""
    if not validate_token(request.token):
        raise HTTPException(status_code=401, detail="è®¤è¯å¤±è´¥ï¼Œè¯·æä¾›æœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
    
    text_processed = f"({request.mode})" + request.text
    output_audio, sr = tts_engine(text_processed, request.speaker)
    audio_type = "music"
    file_path = save_audio(audio_type, output_audio, sr)
    
    return {
        "status": "success",
        "file_path": file_path,
        "text": request.text,
        "speaker": request.speaker,
        "params": {
            "mode": request.mode
        }
    }

@app.post("/api/tts/clone", tags=["TTS"])
async def api_tts_clone(
    text: str = Form(...),
    audio_file: UploadFile = File(...),
    prompt_text: str = Form(...),
    speaker: str = Form("custom_voice"),
    emotion: Optional[str] = Form(None),
    language: Optional[str] = Form(None),
    speed: Optional[str] = Form(None),
    token: str = Form(...),
    auth: bool = Depends(verify_token)
):
    """TTSè¯­éŸ³å…‹éš†APIï¼Œä½¿ç”¨å‚è€ƒéŸ³é¢‘è¿›è¡Œè¯­éŸ³å…‹éš†"""
    if not validate_token(token):
        raise HTTPException(status_code=401, detail="è®¤è¯å¤±è´¥ï¼Œè¯·æä¾›æœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
    
    # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
    temp_audio_path = os.path.join(CACHE_DIR, f"upload_{datetime.now().strftime('%Y%m%d%H%M%S')}.wav")
    with open(temp_audio_path, "wb") as f:
        f.write(await audio_file.read())
    
    # æ„å»ºå…‹éš†å‚æ•°
    clone_speaker = {
        "wav_path": temp_audio_path,
        "speaker": speaker,
        "prompt_text": prompt_text,
    }
    
    # å¤„ç†æ–‡æœ¬
    clone_text = (
        (f"({emotion})" if emotion else "")
        + (f"({language})" if language else "")
        + (f"({speed})" if speed else "")
        + text
    )
    
    # ç”ŸæˆéŸ³é¢‘
    output_audio, sr = tts_engine(clone_text, "", clone_speaker)
    audio_type = "clone"
    file_path = save_audio(audio_type, output_audio, sr)
    
    # è¿”å›ç»“æœ
    return {
        "status": "success",
        "file_path": file_path,
        "text": text,
        "speaker": "cloned",
        "params": {
            "reference_audio": audio_file.filename,
            "prompt_text": prompt_text,
            "emotion": emotion,
            "language": language,
            "speed": speed
        }
    }

@app.get("/api/tts/audio/{file_path:path}", tags=["TTS"])
async def get_audio_file(file_path: str, auth: bool = Depends(verify_token)):
    """è·å–ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶"""
    full_path = os.path.join(DATA_DIR, "output", file_path)
    if not os.path.exists(full_path):
        raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
    
    return FileResponse(full_path, media_type="audio/wav")


def _launch_demo(args, tts_engine):
    # é€‰é¡¹åˆ—è¡¨
    emotion_options = ["é«˜å…´1", "é«˜å…´2", "ç”Ÿæ°”1", "ç”Ÿæ°”2", "æ‚²ä¼¤1", "æ’’å¨‡1"]
    language_options = ["ä¸­æ–‡", "è‹±æ–‡", "éŸ©è¯­", "æ—¥è¯­", "å››å·è¯", "ç²¤è¯­", "å¹¿ä¸œè¯"]
    speed_options = ["æ…¢é€Ÿ1", "æ…¢é€Ÿ2", "å¿«é€Ÿ1", "å¿«é€Ÿ2"]
    speaker_options = ["Tingting"]
    # Gradio ç•Œé¢
    with gr.Blocks() as demo:
        gr.Markdown("## ğŸ™ï¸ Step-Audio-TTS-3B Demo")

        # æ·»åŠ Tokenè®¤è¯è¾“å…¥æ¡†
        auth_token = gr.Textbox(
            label="Authentication Token",
            type="password",
            placeholder="è¯·è¾“å…¥è®¿é—®ä»¤ç‰Œ",
        )

        # æ™®é€šè¯­éŸ³åˆæˆ
        with gr.Tab("Common TTS (æ™®é€šè¯­éŸ³åˆæˆ)"):
            text_input = gr.Textbox(
                label="Input Text (è¾“å…¥æ–‡æœ¬)",
            )
            speaker_input = gr.Dropdown(
                speaker_options,
                label="Speaker Selection (éŸ³è‰²é€‰æ‹©)",
            )
            emotion_input = gr.Dropdown(
                emotion_options,
                label="Emotion Style (æƒ…æ„Ÿé£æ ¼)",
                allow_custom_value=True,
                interactive=True,
            )
            language_input = gr.Dropdown(
                language_options,
                label="Language/Dialect (è¯­è¨€/æ–¹è¨€)",
                allow_custom_value=True,
                interactive=True,
            )
            speed_input = gr.Dropdown(
                speed_options,
                label="Speech Rate (è¯­é€Ÿè°ƒèŠ‚)",
                allow_custom_value=True,
                interactive=True,
            )
            submit_btn = gr.Button("ğŸ”Š Generate Speech (ç”Ÿæˆè¯­éŸ³)")
            output_audio = gr.Audio(
                label="Output Audio (åˆæˆè¯­éŸ³)",
                interactive=False,
            )

            submit_btn.click(
                tts_common,
                inputs=[
                    text_input,
                    speaker_input,
                    emotion_input,
                    language_input,
                    speed_input,
                    auth_token,
                ],
                outputs=output_audio,
            )

        # RAP / å“¼å”±æ¨¡å¼
        with gr.Tab("RAP/Humming Mode (RAP/å“¼å”±æ¨¡å¼)"):
            text_input_rap = gr.Textbox(
                label="Lyrics Input (æ­Œè¯è¾“å…¥)",
            )
            speaker_input = gr.Dropdown(
                speaker_options,
                label="Speaker Selection (éŸ³è‰²é€‰æ‹©)",
            )
            mode_input = gr.Radio(
                ["RAP", "Humming (å“¼å”±)"],
                value="RAP",
                label="Generation Mode (ç”Ÿæˆæ¨¡å¼)",
            )
            submit_btn_rap = gr.Button("ğŸ¤ Generate Performance (ç”Ÿæˆæ¼”ç»)")
            output_audio_rap = gr.Audio(
                label="Performance Audio (æ¼”ç»éŸ³é¢‘)", interactive=False
            )
            submit_btn_rap.click(
                tts_music,
                inputs=[
                    text_input_rap, 
                    speaker_input, 
                    mode_input,
                    auth_token,
                ],
                outputs=output_audio_rap,
            )

        with gr.Tab("Voice Clone (è¯­éŸ³å…‹éš†)"):
            text_input_clone = gr.Textbox(
                label="Target Text (ç›®æ ‡æ–‡æœ¬)",
                placeholder="Text to be synthesized with cloned voice (å¾…å…‹éš†è¯­éŸ³åˆæˆçš„æ–‡æœ¬)",
            )
            audio_input = gr.File(
                label="Reference Audio Upload (å‚è€ƒéŸ³é¢‘ä¸Šä¼ )",
            )
            speaker_prompt = gr.Textbox(
                label="Exact text from reference audio (è¾“å…¥å‚è€ƒéŸ³é¢‘çš„å‡†ç¡®æ–‡æœ¬)",
            )
            emotion_input = gr.Dropdown(
                emotion_options,
                label="Emotion Style (æƒ…æ„Ÿé£æ ¼)",
                allow_custom_value=True,
                interactive=True,
            )
            language_input = gr.Dropdown(
                language_options,
                label="Language/Dialect (è¯­è¨€/æ–¹è¨€)",
                allow_custom_value=True,
                interactive=True,
            )
            speed_input = gr.Dropdown(
                speed_options,
                label="Speech Rate (è¯­é€Ÿè°ƒèŠ‚)",
                allow_custom_value=True,
                interactive=True,
            )
            submit_btn_clone = gr.Button("ğŸ—£ï¸ Synthesize Cloned Speech (åˆæˆå…‹éš†è¯­éŸ³)")
            output_audio_clone = gr.Audio(
                label="Cloned Speech Output (å…‹éš†è¯­éŸ³è¾“å‡º)",
                interactive=False,
            )
            submit_btn_clone.click(
                tts_clone,
                inputs=[
                    text_input_clone,
                    audio_input,
                    speaker_prompt,
                    emotion_input,
                    language_input,
                    speed_input,
                    auth_token,
                ],
                outputs=output_audio_clone,
            )

    # å°†Gradioåº”ç”¨æŒ‚è½½åˆ°FastAPIåº”ç”¨
    gr_app = gr.mount_gradio_app(app, demo, path="/tts")
    return app


if __name__ == "__main__":
    from argparse import ArgumentParser
    import os
    import uvicorn

    parser = ArgumentParser()
    parser.add_argument("--model-path", type=str, required=True, help="Model path.")
    parser.add_argument(
        "--server-name", type=str, default="0.0.0.0", help="Demo server name."
    )
    parser.add_argument(
        "--server-port", type=int, default=7860, help="Demo server port."
    )
    parser.add_argument("--tmp_dir", type=str, default="/tmp/gradio", help="Save path.")

    args = parser.parse_args()
    # ä½¿ç”¨è§£æåçš„å‘½ä»¤è¡Œå‚æ•°è®¾ç½®æ¨¡å‹è·¯å¾„
    model_path = args.model_path
    
    # åŠ è½½æ¨¡å‹
    tokenizer_path = os.path.join(model_path, "Step-Audio-Tokenizer")
    tts_model_path = os.path.join(model_path, "Step-Audio-TTS-3B")
    
    encoder = StepAudioTokenizer(tokenizer_path)
    tts_engine = StepAudioTTS(tts_model_path, encoder)
    
    # æ›´æ–°æ¨¡å‹çŠ¶æ€
    status_tracker.update_model_status("tokenizer", True, tokenizer_path)
    status_tracker.update_model_status("tts", True, tts_model_path)
    
    # å¯åŠ¨åº”ç”¨
    app = _launch_demo(args, tts_engine)
    
    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(
        app, 
        host=args.server_name, 
        port=args.server_port
    )
